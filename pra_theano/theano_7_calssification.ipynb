{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from __future__ import division\n",
    "\n",
    "def accuracy(y_target, y_predict):\n",
    "    correct = np.equal(y_target, y_predict)\n",
    "    accuracy_socere = np.sum(correct) / len(correct) \n",
    "    return accuracy_socere\n",
    "\n",
    "rng = np.random\n",
    "\n",
    "#Data and feature variable\n",
    "N, feats = 400, 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = (rng.randn(N, feats), rng.randint(size=N , low=0, high=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#declare theano symbolic variable\n",
    "x = T.dmatrix('x')\n",
    "y = T.dvector('y')\n",
    "\n",
    "w = theano.shared(rng.randn(feats), name = 'w')\n",
    "b = theano.shared(0.1, name = 'b')\n",
    "\n",
    "#construct expression graph\n",
    "p_1 = T.nnet.sigmoid(T.dot(x, w) + b)\n",
    "prediction = p_1 > 0.5\n",
    "\n",
    "#xent = T.nnet.binary_crossentropy(p_1, y) \n",
    "xent = -y * T.log(p_1) - (1 - y) * T.log(1 - p_1)\n",
    "#cost = xent.mean()\n",
    "cost = xent.mean() - 0.01 * (w**2).sum()\n",
    "\n",
    "gw, gb = T.grad(cost, [w, b])\n",
    "\n",
    "#compile\n",
    "learning_rate = 0.1\n",
    "train = theano.function([x, y], [prediction, xent.mean()], updates=((w, w - learning_rate * gb),(b, b - learning_rate * gb)))\n",
    "predict = theano.function([x], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  1.31290051926\n",
      "accuracy is  0.505\n",
      "loss is  0.179308733232\n",
      "accuracy is  0.9875\n",
      "loss is  0.101845526928\n",
      "accuracy is  1.0\n",
      "loss is  0.0771790089458\n",
      "accuracy is  1.0\n",
      "loss is  0.0657142916187\n",
      "accuracy is  1.0\n",
      "loss is  0.0594480094746\n",
      "accuracy is  1.0\n",
      "loss is  0.0557085164475\n",
      "accuracy is  1.0\n",
      "loss is  0.0533558543766\n",
      "accuracy is  1.0\n",
      "loss is  0.0518245747071\n",
      "accuracy is  1.0\n",
      "loss is  0.0508045480885\n",
      "accuracy is  1.0\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for i in range(500):\n",
    "    pred, err = train(D[0], D[1])\n",
    "    if i % 50 == 0:\n",
    "        print \"loss is \", err\n",
    "        print \"accuracy is \", accuracy(D[1], predict(D[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
